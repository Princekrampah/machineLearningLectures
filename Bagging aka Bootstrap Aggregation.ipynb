{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging aka Bootstrap Aggregating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging algorithm\n",
    "\n",
    "```psuedo code\n",
    "    \n",
    "let n be the total number of bootstrap samples\n",
    "\n",
    "for i = 1 to n do\n",
    "   Draw a bootstrap sample of size m, D1\n",
    "   Train base classifier h1 on D1\n",
    "y_pred = mode{h1(X), ..., hn(X)}     \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Bootstraping Is Done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In bootstraping what we do is we randomly select samples from the original training data with replacement. The size of the bootstrap sample must be equal to that of the original training sample. Example if the original training sample was ``m`` then the size of each bootstrap round must be of size ``m``. Sampling with replacement means some data points can be repeated more than once. \n",
    "\n",
    "Not all data points from the original data will be included in each bootstrap sample since some of them repeat and we don't want to exceed the size ``m``.\n",
    "\n",
    "The once that do not occure in the bootstrap sample are called **Out Of Back** samples or simpley **OOB**. These are just data point that are not included in a given **round**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![bootstrap1](bootstrap1.png)\n",
    "[source](https://www.youtube.com/watch?v=pWSULhaZlQM&list=PLTKMiZHVd_2KyGirGEvKlniaWeLOHhUF3&index=41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Math Behind It\n",
    "\n",
    "### What is the probability of not choosing a given sample\n",
    "\n",
    "probability of choosing a given sample is :\n",
    " ### $$ P = \\frac{1}{m} $$\n",
    "where m = total number of samples\n",
    "\n",
    "Hence probability of not choosing a sample is:\n",
    "\n",
    "### $$ P(not choosen) = \\Big(1 - \\frac{1}{m} \\Big) $$\n",
    "\n",
    "Applying this to the whole sample we, raise it to power ``m`` and we get:\n",
    "\n",
    "### $$ P(not choosen) = \\Big(1 - \\frac{1}{m} \\Big)^m $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In case the data set is very large then:\n",
    "\n",
    "### $$ P(not choosen) = \\frac{1}{e}, m \\to \\infty = 0.368 = 36.8% $$\n",
    "\n",
    "This means that, 36.8% of the data will not be choosen if the dataset was very large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![bootstrap2](bootstrap2.png)\n",
    "[source](https://www.youtube.com/watch?v=pWSULhaZlQM&list=PLTKMiZHVd_2KyGirGEvKlniaWeLOHhUF3&index=41)\n",
    "\n",
    "From the above graph, with 200+ data points, we'll be having around 0.63 or 63% unique data points, the rest are duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview Of Bagging in General\n",
    "\n",
    "NOTE: Majority voting is same as **mode**\n",
    "\n",
    "![bootstrap3](bootstrap3.png)\n",
    "[source](https://www.youtube.com/watch?v=pWSULhaZlQM&list=PLTKMiZHVd_2KyGirGEvKlniaWeLOHhUF3&index=41)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_samples=100, n_features=4,\n",
    "                           n_informative=2, n_redundant=0,\n",
    "                           random_state=0, shuffle=False)\n",
    "\n",
    "clf = BaggingClassifier(base_estimator=SVC(),\n",
    "                        n_estimators=500, \n",
    "                        random_state=0,\n",
    "                        oob_score=True\n",
    "                       ).fit(X, y)\n",
    "\n",
    "clf.predict([[0, 0, 0, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **OOB_score** is computed as the number of correctly predicted rows from the out-of-bag sample. And. **OOB Error** is the number of wrongly classifying the OOB Sample[source](https://www.analyticsvidhya.com/blog/2020/12/out-of-bag-oob-score-in-the-random-forest-algorithm/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB score: 0.89\n"
     ]
    }
   ],
   "source": [
    "print(f\"OOB score: {clf.oob_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The more the ``n_estimators`` the greater the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Bagging Works\n",
    "\n",
    "Bagging works to well do to the fact that it finds average of many base learners hence reducing variance of the base learners when combined. For more watch the ending section of this [video](https://www.youtube.com/watch?v=pWSULhaZlQM&list=PLTKMiZHVd_2KyGirGEvKlniaWeLOHhUF3&index=41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "[Official documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html)\n",
    "\n",
    "[video Resource](https://www.youtube.com/watch?v=pWSULhaZlQM&list=PLTKMiZHVd_2KyGirGEvKlniaWeLOHhUF3&index=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
